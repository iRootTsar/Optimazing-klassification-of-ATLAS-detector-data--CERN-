{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN med Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "#other libraries\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# import random\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "#torch specific\n",
    "import torch\n",
    "import torchvision as torchv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = str(Path.cwd().parents[0].parents[0] / \"methods\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader import *\n",
    "# from plotCreator import *\n",
    "\n",
    "data_path0 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"BH_n4_M10_res50_15000_events.h5\")\n",
    "data_path1 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"PP13-Sphaleron-THR9-FRZ15-NB0-NSUBPALL_res50_15000_events.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhArray = dataToArray(data_path0)\n",
    "sphArray = dataToArray(data_path1)\n",
    "\n",
    "# print(bhArray.shape)\n",
    "# print(sphArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kombinerer dataene for å kunne kjøre gjennom modellen på et samlet datasett\n",
    "dataArray = np.concatenate((bhArray,sphArray),axis=0)\n",
    "\n",
    "# np.shape(dataArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeler tabelle med 1 og 0 (0 = svart hull, 1 = spahleron)\n",
    "labelsArray = np.concatenate((np.zeros(np.shape(bhArray)[0]),np.ones(np.shape(sphArray)[0])),axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sjekk om køyrer på GPU eller CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data 75% i train og 25% i test\n",
    "trainData, testData, trainLabels, testLabels = train_test_split(dataArray, labelsArray, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = torch.from_numpy(trainData)\n",
    "testData = torch.from_numpy(testData)\n",
    "trainLabels = torch.from_numpy(trainLabels)\n",
    "testLabels = torch.from_numpy(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(trainData, trainLabels)\n",
    "test = torch.utils.data.TensorDataset(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(train, shuffle=True, batch_size=50)\n",
    "testLoader = DataLoader(test, shuffle=True, batch_size=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her er vårt CNN modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her kommer modellen inn\n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "\n",
    "        super(ConvModel, self).__init__()\n",
    "        # 2 cov lag blir opprette. Bildene har x, y og z verdi. \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(3*3*256, 128)\n",
    "        self.fc2 = nn.Linear(128,2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x) #to activate function above\n",
    "\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool2d(x,3)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summere modellen sine parametera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 48, 48]             448\n",
      "            Conv2d-2           [-1, 64, 22, 22]           9,280\n",
      "            Conv2d-3            [-1, 256, 9, 9]         147,712\n",
      "            Linear-4                  [-1, 128]         295,040\n",
      "            Linear-5                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 452,738\n",
      "Trainable params: 452,738\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.68\n",
      "Params size (MB): 1.73\n",
      "Estimated Total Size (MB): 2.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "model = ConvModel(0).to(device)\n",
    "summary(model, (3, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\vlads\\AppData\\Local\\Temp\\ipykernel_14040\\3335153958.py:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if config.optimizer is 'adam':\n"
     ]
    }
   ],
   "source": [
    "def trainFunction(config=None):\n",
    "\n",
    "    #init wandb\n",
    "    with wandb.init(project=\"PyTorch\", name=\"convmodel\", config=config):\n",
    "        #initialize variables\n",
    "        model = ConvModel(config.dropout).to(device)\n",
    "\n",
    "        # Teste dette ut: \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        def function_uno(x, y): \n",
    "            long_prob = -1.0 * F.log_softmax(x, 1)\n",
    "            loss = long_prob.gather(1, y.unsqueeze(1))\n",
    "            loss = loss.mean()\n",
    "            return loss\n",
    "\n",
    "        # Teste dette ut: (optimizer og learning rate)\n",
    "        if config.optimizer is 'adam':\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "        #initialize variables end\n",
    "\n",
    "\n",
    "        #data\n",
    "        trainLoader = DataLoader(train, shuffle=True, batch_size=config.batch_size)\n",
    "        testLoader = DataLoader(test, shuffle=True, batch_size=config.batch_size)\n",
    "        #data end\n",
    "        \n",
    "        wandb.watch(model, function_uno, log='all')\n",
    "        \n",
    "        #START\n",
    "        for epoch in range(8):\n",
    "\n",
    "            #training variables\n",
    "            trainRunningLoss = 0.0\n",
    "            correct = 0\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            #training loop\n",
    "            model.train()\n",
    "            for i, data in enumerate(trainLoader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() \n",
    "                output = model(inputs.permute(0,3,1,2)) # bytter på rekkefølge til dimensjonene \n",
    "                output1 = (torch.max(output.to(device), 1)[1]) # den predictede outputtn \n",
    "                y_pred.extend(output1) # Save Prediction\n",
    "                \n",
    "                y_true.extend(labels) # Save Truth\n",
    "                loss = function_uno(output, labels.type(torch.LongTensor).to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step() # Endrer på vekten \n",
    "                \n",
    "                trainRunningLoss += loss.item() * inputs.size(0) #\n",
    "            #training loop end\n",
    "            correct = (torch.FloatTensor(y_pred) == torch.FloatTensor(y_true)).sum()\n",
    "            trainAccuracy = correct / len(y_true)\n",
    "            #training variables end\n",
    "\n",
    "            #test variables\n",
    "            testRunningLoss = 0.0\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            #test loop\n",
    "            model.eval()\n",
    "            for j, data in enumerate(testLoader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                output = model(inputs.permute(0,3,1,2))# Feed Network\n",
    "\n",
    "                output1 = (torch.max(output.to(device), 1)[1])\n",
    "                y_pred.extend(output1) # Save Prediction\n",
    "                \n",
    "                y_true.extend(labels) # Save Truth\n",
    "                loss = function_uno(output, labels.type(torch.LongTensor).to(device))\n",
    "                testRunningLoss += loss.item() * inputs.size(0)\n",
    "            #test loop end\n",
    "\n",
    "            correct = (torch.FloatTensor(y_pred) == torch.FloatTensor(y_true)).sum()\n",
    "            testAccuracy = correct / len(y_true)\n",
    "            testRunningLoss = testRunningLoss/len(bhArray)\n",
    "            trainRunningLoss = trainRunningLoss/len(bhArray)\n",
    "            #test variables end\n",
    "            \n",
    "            #Here comes print\n",
    "            wandb.log({\"Train epoch_loss\":trainRunningLoss, \"Test epoch_loss\": testRunningLoss, \"Train accuracy\": trainAccuracy,\"Test accuracy\": testAccuracy})\n",
    "\n",
    "        #END"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denne biten kun for å sette opp prosjektet i wandb for første gang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Weights and biases set up\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     name=\"convmodel\",\n",
    "#     project=\"PyTorch\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"epochs\": 50,\n",
    "#     'batch_size': 100,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece starts script with hyperparameters given and then simulate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: k8r3yjlc\n",
      "Sweep URL: https://wandb.ai/vladpus/PyTorch/sweeps/k8r3yjlc\n"
     ]
    }
   ],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'grid',\n",
    "    'name': 'sweep',\n",
    "    'metric': {\n",
    "        'goal': 'maximize', \n",
    "        'name': 'Test accuracy'\n",
    "        },\n",
    "    'parameters': {\n",
    "        'batch_size': {'values': [8]},\n",
    "        'learning_rate': {'values': [0.01]},\n",
    "        'optimizer': {'values': ['adam']},\n",
    "        'dropout': {'values': [0.5]}\n",
    "     }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"PyTorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l2rcvfz9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvladcivilgin\u001b[0m (\u001b[33mvladpus\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\vlads\\Desktop\\HVL\\Studie\\DAT191 Bachelor\\Optimazing klassification of ATLAS detector data (CERN)\\notebooks\\pyTorch\\wandb\\run-20230306_114414-l2rcvfz9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vladpus/PyTorch/runs/l2rcvfz9' target=\"_blank\">convmodel</a></strong> to <a href='https://wandb.ai/vladpus/PyTorch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/vladpus/PyTorch/sweeps/k8r3yjlc' target=\"_blank\">https://wandb.ai/vladpus/PyTorch/sweeps/k8r3yjlc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vladpus/PyTorch' target=\"_blank\">https://wandb.ai/vladpus/PyTorch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vladpus/PyTorch/sweeps/k8r3yjlc' target=\"_blank\">https://wandb.ai/vladpus/PyTorch/sweeps/k8r3yjlc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vladpus/PyTorch/runs/l2rcvfz9' target=\"_blank\">https://wandb.ai/vladpus/PyTorch/runs/l2rcvfz9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4a1005992346898f1bd19903c1a069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.016 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.084245…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">convmodel</strong> at: <a href='https://wandb.ai/vladpus/PyTorch/runs/l2rcvfz9' target=\"_blank\">https://wandb.ai/vladpus/PyTorch/runs/l2rcvfz9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230306_114414-l2rcvfz9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run l2rcvfz9 errored: AttributeError(\"'NoneType' object has no attribute 'dropout'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run l2rcvfz9 errored: AttributeError(\"'NoneType' object has no attribute 'dropout'\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=trainFunction, count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT255",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d664d9bb41b9d3fab976584bc1e1a8560719b55467dc411ee4a441179259a613"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

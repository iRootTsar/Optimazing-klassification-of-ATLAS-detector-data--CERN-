{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN med Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "#other libraries\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# import random\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#torch specific\n",
    "import torch\n",
    "import torchvision as torchv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = str(Path.cwd().parents[0].parents[0] / \"methods\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader import *\n",
    "# from plotCreator import *\n",
    "\n",
    "data_path0 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"BH_n4_M10_res50_15000_events.h5\")\n",
    "data_path1 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"PP13-Sphaleron-THR9-FRZ15-NB0-NSUBPALL_res50_15000_events.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhArray = dataToArray(data_path0)\n",
    "sphArray = dataToArray(data_path1)\n",
    "\n",
    "# print(bhArray.shape)\n",
    "# print(sphArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kombinerer dataene for å kunne kjøre gjennom modellen på et samlet datasett\n",
    "dataArray = np.concatenate((bhArray,sphArray),axis=0)\n",
    "\n",
    "# np.shape(dataArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeler tabelle med 1 og 0 (0 = svart hull, 1 = spahleron)\n",
    "labelsArray = np.concatenate((np.zeros(np.shape(bhArray)[0]),np.ones(np.shape(sphArray)[0])),axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sjekk om køyrer på GPU eller CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data 75% i train og 25% i test\n",
    "trainData, testData, trainLabels, testLabels = train_test_split(dataArray, labelsArray, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = torch.from_numpy(trainData)\n",
    "testData = torch.from_numpy(testData)\n",
    "trainLabels = torch.from_numpy(trainLabels)\n",
    "testLabels = torch.from_numpy(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(trainData, trainLabels)\n",
    "test = torch.utils.data.TensorDataset(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(train, shuffle=True, batch_size=50)\n",
    "testLoader = DataLoader(test, shuffle=True, batch_size=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her er vårt CNN modell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her skal det komme endrigane for å tilpasse første CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her kommer modellen inn\n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "\n",
    "        super(ConvModel, self).__init__()\n",
    "        # 2 cov lag blir opprette. Bildene har x, y og z verdi. \n",
    "        \n",
    "        # Define the convolutional layers with rotational and reflectional symmetry filters\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0)\n",
    "        self.conv1_filter = nn.Parameter(torch.ones((16, 3, 3, 3)))\n",
    "        self.conv1_filter.detach_()\n",
    "        \n",
    "        self.conv1_filter[:, :, 1, 1] = 0  # set the center of the filter to zero\n",
    "        self.conv1_filter[:, :, :, 1] = self.conv1_filter.flip(dims=[3])  # set the right half of the filter\n",
    "        self.conv1_filter[:, :, 0, 0] = self.conv1_filter[:, :, 2, 2]  # set the top-left and bottom-right corners\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(3*3*256, 128)\n",
    "        self.fc2 = nn.Linear(128,2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    #FIX THIS ASSHOLE\n",
    "    def forward(self, x:Tensor):\n",
    "        x = F.conv2d(x, self.conv1_filter, bias=self.conv1.bias, stride=1, padding=1)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,3)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    " \n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summere modellen sine parametera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[16, 3, 3, 3]}, size=[16, 3, 3]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m \u001b[39mimport\u001b[39;00m summary\n\u001b[1;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m ConvModel(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      4\u001b[0m summary(model, (\u001b[39m3\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m50\u001b[39m))\n",
      "Cell \u001b[1;32mIn[66], line 14\u001b[0m, in \u001b[0;36mConvModel.__init__\u001b[1;34m(self, dropout)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1_filter\u001b[39m.\u001b[39mdetach_()\n\u001b[0;32m     13\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1_filter[:, :, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# set the center of the filter to zero\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1_filter[:, :, :, \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1_filter\u001b[39m.\u001b[39mflip(dims\u001b[39m=\u001b[39m[\u001b[39m3\u001b[39m])  \u001b[39m# set the right half of the filter\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1_filter[:, :, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1_filter[:, :, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m]  \u001b[39m# set the top-left and bottom-right corners\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv2d(in_channels\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, out_channels\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[16, 3, 3, 3]}, size=[16, 3, 3]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = ConvModel(0).to(device)\n",
    "summary(model, (3, 50, 50))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trene modellen vår"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainFunction(config=None):\n",
    "\n",
    "        #initialize variables\n",
    "        model = ConvModel(config.dropout).to(device)\n",
    "\n",
    "        #data\n",
    "        trainLoader = DataLoader(train, shuffle=True, batch_size=config.batch_size)\n",
    "        testLoader = DataLoader(test, shuffle=True, batch_size=config.batch_size)\n",
    "        #data end\n",
    "        \n",
    "        \n",
    "        #Her komemr data augmetnation?\n",
    "        \n",
    "        \n",
    "        #START\n",
    "        for epoch in range(20):\n",
    "\n",
    "            #training variables\n",
    "  \n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            \n",
    "            #training loop\n",
    "            model.train()\n",
    "            for i, data in enumerate(trainLoader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                output = model(inputs.permute(0,3,1,2)) # change \n",
    "                output1 = (torch.max(output.to(device), 1)[1]) #predicted output\n",
    "                \n",
    "                y_pred.extend(output1) # Save Prediction\n",
    "                \n",
    "                y_true.extend(labels) # Save Truth\n",
    "           \n",
    "            #test variables\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            \n",
    "            #test loop\n",
    "            model.eval()\n",
    "            for j, data in enumerate(testLoader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                output = model(inputs.permute(0,3,1,2))# Feed Network\n",
    "                output1 = (torch.max(output.to(device), 1)[1])\n",
    "                y_pred.extend(output1) # Save Prediction\n",
    "                \n",
    "                y_true.extend(labels) # Save Truth\n",
    "            #test loop end\n",
    "            \n",
    "            # #Here comes print\n",
    "            \n",
    "        #END"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kanskje lurt å se på wandb for å deploye modellen "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT255",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d664d9bb41b9d3fab976584bc1e1a8560719b55467dc411ee4a441179259a613"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN med Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "#torch \n",
    "import torch\n",
    "import torchvision as torchv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = str(Path.cwd().parents[0].parents[0] / \"methods\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader import *\n",
    "# from plotCreator import *\n",
    "\n",
    "data_path0 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"BH_n4_M10_res50_15000_events.h5\")\n",
    "data_path1 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"PP13-Sphaleron-THR9-FRZ15-NB0-NSUBPALL_res50_15000_events.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhArray = dataToArray(data_path0)\n",
    "sphArray = dataToArray(data_path1)\n",
    "\n",
    "# print(bhArray.shape)\n",
    "# print(sphArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kombinerer dataene for å kunne kjøre gjennom modellen på et samlet datasett\n",
    "dataArray = np.concatenate((bhArray,sphArray),axis=0)\n",
    "\n",
    "# np.shape(dataArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeler tabelle med 1 og 0 (0 = svart hull, 1 = spahleron)\n",
    "labelsArray = np.concatenate((np.zeros(np.shape(bhArray)[0]),np.ones(np.shape(sphArray)[0])),axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sjekk om køyrer på GPU eller CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data 75% i train og 25% i test\n",
    "trainData, testData, trainLabels, testLabels = train_test_split(dataArray, labelsArray, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = torch.from_numpy(trainData)\n",
    "testData = torch.from_numpy(testData)\n",
    "trainLabels = torch.from_numpy(trainLabels)\n",
    "testLabels = torch.from_numpy(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformere numpy til tensor\n",
    "train = torch.utils.data.TensorDataset(trainData, trainLabels)\n",
    "test = torch.utils.data.TensorDataset(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sette data til å vere dataloaders\n",
    "trainLoader = DataLoader(train, shuffle=True, batch_size=50)\n",
    "testLoader = DataLoader(test, shuffle=True, batch_size=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her er vårt CNN modell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her skal det komme endrigane for å tilpasse første CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her kommer modellen inn\n",
    "class ConvModel(nn.Module):\n",
    "    #Husk art her brukes droput for å unngå overfitting\n",
    "    def __init__(self, dropout):\n",
    "\n",
    "        super(ConvModel, self).__init__()\n",
    "        #opprette conv lag. Bildene har 3 lag \n",
    "        \n",
    "        #Dette funker\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0)\n",
    "        \n",
    "        #Her prøver å tweake på første pooling laget\n",
    "        # Define the convolutional layers with rotational and reflectional symmetry filters\n",
    "        # self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0)\n",
    "        # self.conv1_filter = nn.Parameter(torch.ones((16, 3, 3, 3)))\n",
    "        # self.conv1_filter.detach_()\n",
    "        \n",
    "        # self.conv1_filter[:, :, 1, 1] = 0  # set the center of the filter to zero\n",
    "        # self.conv1_filter[:, :, :, 1] = self.conv1_filter.flip(dims=[3])  # set the right half of the filter\n",
    "        # self.conv1_filter[:, :, 0, 0] = self.conv1_filter[:, :, 2, 2]  # set the top-left and bottom-right corners\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=0)\n",
    "        #kanskje ha flere layers?\n",
    "\n",
    "        #Unchange\n",
    "        self.fc1 = nn.Linear(3*3*256, 128)\n",
    "        self.fc2 = nn.Linear(128,2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    #Enten her eller over skal komme endringane for convolutional layer\n",
    "    def forward(self, x:Tensor):\n",
    "        \n",
    "        #x = F.conv2d(x, self.conv1_filter, bias=self.conv1.bias, stride=1, padding=1)\n",
    "        x= self.conv1(x)\n",
    "        x = F.relu(x) \n",
    "        \n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,3)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summere modellen sine parametera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 48, 48]             448\n",
      "            Conv2d-2           [-1, 64, 22, 22]           9,280\n",
      "            Conv2d-3            [-1, 256, 9, 9]         147,712\n",
      "            Linear-4                  [-1, 128]         295,040\n",
      "            Linear-5                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 452,738\n",
      "Trainable params: 452,738\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.68\n",
      "Params size (MB): 1.73\n",
      "Estimated Total Size (MB): 2.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "#Her måp det endres sidan den aksepterer ikek parametere gitt\n",
    "model = ConvModel(0).to(device)\n",
    "summary(model, (3, 50, 50))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trene modellen vår her, muligens implementere wandb her for å deploye modellen og se progressjonen og sammenligne med andre modeller samnt data agumentering kan komme med i denne delen av koden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, criterion, n_epochs):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.permute(0, 3, 1, 2)).float()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Test\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "                outputs = model(inputs.permute(0, 3, 1, 2)).float()\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        test_acc = 100 * correct / total\n",
    "        test_loss /= len(test_loader)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gjør kall på modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.6935, Train Accuracy: 75.22%\n",
      "Test Loss: 0.4564, Test Accuracy: 79.03%\n",
      "Epoch 2/10\n",
      "Train Loss: 0.3640, Train Accuracy: 84.38%\n",
      "Test Loss: 0.3249, Test Accuracy: 85.97%\n",
      "Epoch 3/10\n",
      "Train Loss: 0.3017, Train Accuracy: 87.44%\n",
      "Test Loss: 0.3110, Test Accuracy: 86.60%\n",
      "Epoch 4/10\n",
      "Train Loss: 0.2670, Train Accuracy: 89.07%\n",
      "Test Loss: 0.2963, Test Accuracy: 87.64%\n",
      "Epoch 5/10\n",
      "Train Loss: 0.2505, Train Accuracy: 89.81%\n",
      "Test Loss: 0.2965, Test Accuracy: 87.73%\n",
      "Epoch 6/10\n",
      "Train Loss: 0.2258, Train Accuracy: 90.76%\n",
      "Test Loss: 0.2984, Test Accuracy: 87.33%\n",
      "Epoch 7/10\n",
      "Train Loss: 0.2098, Train Accuracy: 91.42%\n",
      "Test Loss: 0.3484, Test Accuracy: 86.67%\n",
      "Epoch 8/10\n",
      "Train Loss: 0.1915, Train Accuracy: 92.34%\n",
      "Test Loss: 0.2909, Test Accuracy: 88.16%\n",
      "Epoch 9/10\n",
      "Train Loss: 0.1719, Train Accuracy: 92.88%\n",
      "Test Loss: 0.3162, Test Accuracy: 87.75%\n",
      "Epoch 10/10\n",
      "Train Loss: 0.1561, Train Accuracy: 93.96%\n",
      "Test Loss: 0.4136, Test Accuracy: 86.59%\n"
     ]
    }
   ],
   "source": [
    "model = ConvModel(dropout=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train(model, trainLoader, testLoader, optimizer, criterion, n_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT255",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d664d9bb41b9d3fab976584bc1e1a8560719b55467dc411ee4a441179259a613"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

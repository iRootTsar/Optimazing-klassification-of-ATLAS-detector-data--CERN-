{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "#torch \n",
    "import torch\n",
    "import torchvision as torchv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = str(Path.cwd().parents[0].parents[0] / \"methods\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader import *\n",
    "# from plotCreator import *\n",
    "\n",
    "data_path0 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"BH_n4_M10_res50_15000_events.h5\")\n",
    "data_path1 = str(Path.cwd().parents[0].parents[0] / \"data\" / \"PP13-Sphaleron-THR9-FRZ15-NB0-NSUBPALL_res50_15000_events.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhArray = dataToArray(data_path0)\n",
    "sphArray = dataToArray(data_path1)\n",
    "\n",
    "# print(bhArray.shape)\n",
    "# print(sphArray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kombinerer dataene for å kunne kjøre gjennom modellen på et samlet datasett\n",
    "dataArray = np.concatenate((bhArray,sphArray),axis=0)\n",
    "\n",
    "# np.shape(dataArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeler tabelle med 1 og 0 (0 = svart hull, 1 = spahleron)\n",
    "labelsArray = np.concatenate((np.zeros(np.shape(bhArray)[0]),np.ones(np.shape(sphArray)[0])),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data 75% i train og 25% i test\n",
    "trainData, testData, trainLabels, testLabels = train_test_split(dataArray, labelsArray, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = torch.from_numpy(trainData)\n",
    "testData = torch.from_numpy(testData)\n",
    "trainLabels = torch.from_numpy(trainLabels)\n",
    "testLabels = torch.from_numpy(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformere numpy til tensor\n",
    "train = torch.utils.data.TensorDataset(trainData, trainLabels)\n",
    "test = torch.utils.data.TensorDataset(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sette data til å vere dataloaders\n",
    "trainLoader = DataLoader(train, shuffle=True, batch_size=50)\n",
    "testLoader = DataLoader(test, shuffle=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the dataloader and print out each batch of data\n",
    "# for batch_idx, (data_batch, target_batch) in enumerate(trainLoader):\n",
    "#     print(f\"Batch {batch_idx}:\")\n",
    "#     print(f\"Data: {data_batch}\")\n",
    "#     print(f\"Targets: {target_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the ConvModel class\n",
    "class ConvModel(nn.Module):\n",
    "    #Constructor that initializes the layers of the model\n",
    "    def __init__(self, dropout):\n",
    "\n",
    "        super(ConvModel, self).__init__()\n",
    "        #opprette conv lag. Bildene har 3 lag \n",
    "        \n",
    "        #Dette funker ikke rør\n",
    "        #Define convolutional layers for the input image\n",
    "        #Input image has 3 challes, 3 layers\n",
    "        #The first convolutional layer has 16 output channels and uses a kernel size of 3x3\n",
    "        #ANd padding is set to 0\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=0)\n",
    "        #kanskje ha flere layers?\n",
    "\n",
    "        #Unchange\n",
    "        #Define fully connected layers\n",
    "        #Input size to the first fully connected layer is 3*3*256\n",
    "        #The first fully connected layer has 128 output units\n",
    "        #The secon fully connected layer has 2 output units\n",
    "        self.fc1 = nn.Linear(3*3*256, 128)\n",
    "        self.fc2 = nn.Linear(128,2)\n",
    "\n",
    "        #Define the dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    #Enten her eller over skal komme endringane for convolutional layer\n",
    "    def forward(self, x:Tensor):\n",
    "        \n",
    "        #x = F.conv2d(x, self.conv1_filter, bias=self.conv1.bias, stride=1, padding=1)\n",
    "        #Apply first conv layer\n",
    "        x= self.conv1(x)\n",
    "        #Apply relu activation function\n",
    "        x = F.relu(x) \n",
    "        #Apply max pooling with a kernel size 2\n",
    "        x = F.max_pool2d(x,2)\n",
    "        #Apply the second conv layer\n",
    "        x = self.conv2(x)\n",
    "        #Apply relu activation function\n",
    "        x = F.relu(x)\n",
    "        #Apply max pooling with a kernel size of 2\n",
    "        x = F.max_pool2d(x,2)\n",
    "        #Apply the third conv layer\n",
    "        x = self.conv3(x)\n",
    "        #Apply relu activation function\n",
    "        x = F.relu(x)\n",
    "        #Appply max pooling with a kernel size 3\n",
    "        x = F.max_pool2d(x,3)\n",
    "        #Flatten the output of the conv layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        #Apply the first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        #Apply relu activation function\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        #Apply teh second fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        #Apply droput to layers??\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m \u001b[39mimport\u001b[39;00m summary\n\u001b[0;32m      3\u001b[0m \u001b[39m#Her måp det endres sidan den aksepterer ikke parametere gitt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[39m=\u001b[39m ConvModel(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "#Her måp det endres sidan den aksepterer ikke parametere gitt\n",
    "model = ConvModel(0).to(device)\n",
    "summary(model, (3, 50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, optimizer, criterion, n_epochs):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    #Start epoch\n",
    "    for epoch in range(n_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        \n",
    "        #Train loop\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.permute(0, 3, 1, 2)).float()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        #Train loop end\n",
    "        \n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Test\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device).float(), labels.to(device).long()\n",
    "                outputs = model(inputs.permute(0, 3, 1, 2)).float()\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        test_acc = 100 * correct / total\n",
    "        test_loss /= len(test_loader)\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.7604, Train Accuracy: 66.08%\n",
      "Test Loss: 0.4517, Test Accuracy: 78.24%\n",
      "Epoch 2/10\n",
      "Train Loss: 0.5026, Train Accuracy: 73.61%\n",
      "Test Loss: 0.3925, Test Accuracy: 83.64%\n",
      "Epoch 3/10\n",
      "Train Loss: 0.4681, Train Accuracy: 75.15%\n",
      "Test Loss: 0.3734, Test Accuracy: 83.61%\n",
      "Epoch 4/10\n",
      "Train Loss: 0.4399, Train Accuracy: 76.96%\n",
      "Test Loss: 0.3304, Test Accuracy: 85.65%\n",
      "Epoch 5/10\n",
      "Train Loss: 0.4272, Train Accuracy: 77.28%\n",
      "Test Loss: 0.3357, Test Accuracy: 85.67%\n",
      "Epoch 6/10\n",
      "Train Loss: 0.4212, Train Accuracy: 77.30%\n",
      "Test Loss: 0.3672, Test Accuracy: 84.45%\n",
      "Epoch 7/10\n",
      "Train Loss: 0.4082, Train Accuracy: 77.76%\n",
      "Test Loss: 0.3762, Test Accuracy: 82.57%\n",
      "Epoch 8/10\n",
      "Train Loss: 0.3999, Train Accuracy: 78.57%\n",
      "Test Loss: 0.2986, Test Accuracy: 87.56%\n",
      "Epoch 9/10\n",
      "Train Loss: 0.4019, Train Accuracy: 78.55%\n",
      "Test Loss: 0.3058, Test Accuracy: 87.17%\n",
      "Epoch 10/10\n",
      "Train Loss: 0.3914, Train Accuracy: 78.88%\n",
      "Test Loss: 0.3074, Test Accuracy: 87.45%\n"
     ]
    }
   ],
   "source": [
    "model = ConvModel(dropout=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train(model, trainLoader, testLoader, optimizer, criterion, n_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT255",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
